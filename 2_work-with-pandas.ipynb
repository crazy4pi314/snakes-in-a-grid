{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2ee7a3ab",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<img src=\"img/tutorial-grid-snakes-light-header.svg\" alt=\"tutorial-logo\" style=\"width: 100%;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5581198",
   "metadata": {},
   "source": [
    "# Working with spreadsheets with Pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cd81cba",
   "metadata": {},
   "source": [
    "In this section of the tutorial, we will learn how to work with data and spreadsheets using the [`pandas`](https://pandas.pydata.org/) library in Python.\n",
    "\n",
    "> NB: If you are not running this in a dev container, make sure you check the readme for setup instructions!\n",
    "\n",
    "Let's start by importing pandas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5f4c47a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3a6246a",
   "metadata": {},
   "source": [
    "## Reading our data into pandas\n",
    "\n",
    "The tabular data you want to work with in pandas and then export to a spreadsheet can start in a variety of formats. Some common formats are:\n",
    "- XSLX (Excel spreadsheets)\n",
    "- ODF (Open Document Format)\n",
    "- CSV (comma-separated values)\n",
    "- JSON (JavaScript Object Notation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1ebfd61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets start by creating a DataFrame from a csv file\n",
    "acnh_fish_df = pd.read_csv('sample-data/animal-crossing/fish.csv')\n",
    "acnh_fish_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97e2bf3f",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "We can also create a DataFrame by loading data from a xlsx file:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3e62669",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "sports_df = pd.read_excel(\"sample-data/summer-sports/summer-sports.xlsx\")\n",
    "sports_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29360dd9",
   "metadata": {},
   "source": [
    "We need to have a bit more control over how we are reading the xlsx file, so let's look at the options we have for the `read_excel` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1197e558",
   "metadata": {},
   "outputs": [],
   "source": [
    "help(pd.read_excel) # or ?? pd.read_excel in jupyter cell magic syntax"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9c62e2a",
   "metadata": {},
   "source": [
    "The most likely ones we will need are:\n",
    "\n",
    "**General**\n",
    "- `sheet_name`: the name of the sheet we want to read from the xlsx file\n",
    "    - pandas will read the first sheet by default\n",
    "- `engine`: the engine to use to read the xlsx file, for the most part pandas will guess the right one!\n",
    "    - `openpyxl` supports newer Excel file formats\n",
    "    - `calamine` supports Excel (.xls, .xlsx, .xlsm, .xlsb) and OpenDocument (.ods) file formats\n",
    "    - `odf` supports OpenDocument file formats (.odf, .ods, .odt)\n",
    "    - `pyxlsb` supports Binary Excel files\n",
    "    - `xlrd` supports old-style Excel files (.xls)\n",
    "\n",
    "> N.B. If you need a specific engine you may need to install it as they are optional dependancies.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c581175",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choosing more than one sheet returns a dictionary of DataFrames\n",
    "sports_data = pd.read_excel(\"sample-data/summer-sports/summer-sports.xlsx\",\n",
    "                            sheet_name=[\"README\", \"data\"]\n",
    "                            )\n",
    "sports_data[\"data\"] "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "098ab5bb",
   "metadata": {},
   "source": [
    "We can test the `engine` option by reading an ods formatted file of the same data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71ab34d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "sports_info = pd.read_excel(\"sample-data/summer-sports/summer-sports.ods\",\n",
    "                            sheet_name=[\"README\", \"data\"],\n",
    "                            engine=\"odf\"\n",
    "                            )\n",
    "sports_info[\"data\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c26d50f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Our readme sheet is now a DataFrame too, but we can add it as\n",
    "# metadata to the data DataFrame\n",
    "\n",
    "sports_data = sports_info[\"data\"]\n",
    "sports_data.attrs = {\"metadata\" : sports_info[\"README\"]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5a7b8d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "sports_data.attrs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6b9ed98",
   "metadata": {},
   "source": [
    "**Rows**\n",
    "- `header`: the row number to use as the column names\n",
    "    - uses the first row by default\n",
    "- `skiprows`: the number of rows to skip at the beginning of the file\n",
    "    - will not skip any rows by default\n",
    "- `nrows`: the number of rows to read from the file\n",
    "    - reads all rows by default"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b2de319",
   "metadata": {},
   "source": [
    "**Columns**\n",
    "- `index_col`: the column number to use as the index\n",
    "    - uses a default integer index\n",
    "- `usecols`: the columns to read from the xlsx file\n",
    "    - reads all columns by default\n",
    "- `dtype`: the data type to use for the columns\n",
    "    - tries to infer the data type from the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e1197e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The fish alreay have an index column, and let's set the data \n",
    "# type of the color columns to category\n",
    "\n",
    "acnh_fish_df = pd.read_csv('sample-data/animal-crossing/fish.csv', \n",
    "                           index_col=0, \n",
    "                           dtype={\"Color 1\":'category', \n",
    "                                  \"Color 2\":'category'}\n",
    "                           )\n",
    "acnh_fish_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "183b7ef9",
   "metadata": {},
   "source": [
    "**Data**\n",
    "- `parse_dates`: whether to parse dates. \n",
    "    - If not specified, pandas will not parse dates by default.\n",
    "- `na_values`: the values to consider as missing values. \n",
    "    - If not specified, pandas will use a default set of missing values.\n",
    "- `converters`: the functions to use to convert the data in the columns. \n",
    "    - If not specified, pandas will use a default set of converters.\n",
    "- `thousands`: the thousands separator to use. \n",
    "    - If not specified, pandas will use a default thousands separator.\n",
    "- `decimal`: the decimal separator to use. \n",
    "    - If not specified, pandas will use a default decimal separator."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34c70bab",
   "metadata": {},
   "source": [
    "Let's use the `converters` option to make the time of day values in the month columns more useable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36517c63",
   "metadata": {},
   "outputs": [],
   "source": [
    "from enum import Enum\n",
    "\n",
    "class TimeOfDay(Enum):\n",
    "   am = 1\n",
    "   pm = 2\n",
    "   all_day = 3\n",
    "\n",
    "def time_of_day(time_period:str) -> TimeOfDay:\n",
    "      if time_period == \"All day\":\n",
    "         return TimeOfDay.all_day\n",
    "      elif time_period == \"4 AM – 9 PM\":\n",
    "         return TimeOfDay.am\n",
    "      elif time_period == \"9 AM – 4 PM\":\n",
    "         return TimeOfDay.pm\n",
    "      else:\n",
    "         return None\n",
    "\n",
    "acnh_fish_df = pd.read_csv('sample-data/animal-crossing/fish.csv', \n",
    "                           index_col=0, \n",
    "                           dtype={\"Color 1\":'category', \n",
    "                                  \"Color 2\":'category'},\n",
    "                           \n",
    "                           converters={\"NH Jan\": time_of_day}\n",
    "                        )\n",
    "acnh_fish_df[\"NH Jan\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d087cd6d",
   "metadata": {},
   "source": [
    "We can continue doing all the good data cleaning we all love like:\n",
    "\n",
    "- missing values\n",
    "- duplicates\n",
    "- data types\n",
    "- renaming columns\n",
    "- aggregating data\n",
    "\n",
    "... but we are here to learn about spreadsheets so let's move on to how to export our pandas data to a spreadsheet!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e0e0681",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## How to export your DataFrame to a spreadsheet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcfd5dc0",
   "metadata": {},
   "source": [
    "- If you have only one DataFrame, you can use `to_excel` with a path to the file you want to save to.\n",
    "\n",
    "- If you want to combine multiple DataFrames into one spreadsheet, you can use `ExcelWriter` to create a new Excel file and then use `to_excel` with a reference to the `ExcelWriter` object to write each DataFrame to the same file, usually as seperate sheets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50141a89",
   "metadata": {},
   "outputs": [],
   "source": [
    "acnh_fish_df.to_excel(\n",
    "    \"sample-data/animal-crossing/acnh-fish.xlsx\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad67e523",
   "metadata": {},
   "outputs": [],
   "source": [
    "acnh_bug_df = pd.read_csv('sample-data/animal-crossing/insects.csv')\n",
    "acnh_fossil_df = pd.read_csv('sample-data/animal-crossing/fossils.csv')\n",
    "acnh_art_df = pd.read_csv('sample-data/animal-crossing/art.csv')\n",
    "\n",
    "# Let's combine all the item lists into one Excel file\n",
    "with pd.ExcelWriter('sample-data/animal-crossing/museum.xlsx') as writer:  \n",
    "    acnh_bug_df.to_excel(writer, sheet_name='bugs')\n",
    "    acnh_fossil_df.to_excel(writer, sheet_name='fossils')\n",
    "    acnh_art_df.to_excel(writer, sheet_name='art')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0431aa88",
   "metadata": {},
   "source": [
    "There are some similar options for the `to_excel` function as there are for the `read_excel` function."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
